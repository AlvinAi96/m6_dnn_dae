{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/notebook/code/group/intention_rec/lclibs already exist\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "def add_path(path):\n",
    "    if path not in sys.path:\n",
    "        sys.path.append(path)\n",
    "        print(path, 'added')\n",
    "    else:\n",
    "        print(path, 'already exist')\n",
    "# add_path('./lclibs')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "\n",
    "from forecasters import *\n",
    "\n",
    "def read_history(file):\n",
    "    df = pd.read_csv(file, header=0)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.rename(columns={'Adjusted_close':'Adj Close'}, inplace=True)\n",
    "    return df\n",
    "    \n",
    "# TODO: read data to be refined,use 'data_read.py'\n",
    "data_dir = '../data'\n",
    "\n",
    "# load history data\n",
    "files = os.listdir(data_dir)\n",
    "data = []\n",
    "for file in files:\n",
    "    stock = file.replace('.csv', '')\n",
    "    file = os.path.join(data_dir, file)\n",
    "    df = read_history(file)\n",
    "    df['stock'] = stock.strip()\n",
    "    data.append(df)\n",
    "\n",
    "data = pd.concat(data)\n",
    "\n",
    "# Fill in the missing dates\n",
    "dates = data[['Date']].drop_duplicates()\n",
    "dates['x'] = 1\n",
    "stocks = data[['stock']].drop_duplicates()\n",
    "stocks['x'] = 1\n",
    "ds = dates.merge(stocks)\n",
    "data = ds.merge(data, how='left').drop('x', axis=1).sort_values(['stock', 'Date']).fillna(method='ffill')\n",
    "\n",
    "### add label\n",
    "trading_dates = data['Date'].values\n",
    "dates = pd.date_range(trading_dates.min(), trading_dates.max())\n",
    "dates = pd.DataFrame(dates, columns=['date'])\n",
    "dates['isin'] = dates['date'].isin(trading_dates)\n",
    "dates['last_trading_date'] = dates['date']\n",
    "dates.loc[~dates['isin'], 'last_trading_date'] = None\n",
    "dates['last_trading_date'] = dates['last_trading_date'].fillna(method='ffill')\n",
    "\n",
    "last_trading_date_dic = dict(zip(dates['date'], dates['last_trading_date']))\n",
    "\n",
    "data['date_4w'] = data['Date'] + pd.Timedelta(days=28)  \n",
    "data['date_4w'] = data['date_4w'].apply(lambda x:last_trading_date_dic.get(x, None)) # # 4周后上一个交易日\n",
    "next_prices = data[['Date', 'stock', 'Adj Close']]\n",
    "next_prices.columns = ['date_4w', 'stock', 'next_price']\n",
    "data = data.merge(next_prices, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.stock.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "returns = {}\n",
    "for stock in data.stock.unique():\n",
    "    tmp = data[data.stock == stock]\n",
    "    tmp['next Close'] = tmp['Adj Close'].diff()#.iloc[1:].reset_index(drop=True)\n",
    "    tmp = tmp.drop_duplicates(subset='Date', keep='first')\n",
    "    return_single = tmp['next Close'] / tmp['Adj Close'].shift(1)\n",
    "    if len(return_single) > 1287:\n",
    "        print(stock)\n",
    "    returns[stock] = return_single.iloc[1:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1284"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(returns[key]) for key in returns.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(returns).to_csv('real_returns_0501.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.DataFrame(returns) < -1).sum().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}